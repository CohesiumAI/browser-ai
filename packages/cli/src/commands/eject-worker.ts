/**
 * Eject worker command.
 * CDC v2026.8 ¬ß16.4 ‚Äî DX External worker
 * 
 * Copies worker files to project's public directory for CSP compliance.
 * "V1.0 : CLI `npx browser-ai eject-worker`"
 */

import fs from 'fs-extra';
import path from 'path';
import chalk from 'chalk';

export interface EjectWorkerOptions {
  output: string;
  force: boolean;
  provider: 'webllm' | 'wasm' | 'all';
}

const WORKER_FILES = {
  webllm: [
    {
      name: 'webllm-worker.js',
      content: `/**
 * WebLLM Worker ‚Äî External worker for CSP compliance.
 * Generated by @cohesiumai/cli eject-worker
 * CDC v2026.8 ¬ß16.4
 */

// Import WebLLM engine
importScripts('https://cdn.jsdelivr.net/npm/@mlc-ai/web-llm@0.2.73/dist/web-llm.min.js');

let engine = null;

self.onmessage = async (event) => {
  const { type, payload, epoch, seq } = event.data;

  try {
    switch (type) {
      case 'INIT': {
        const { modelId, config } = payload;
        engine = new webllm.MLCEngine();
        await engine.reload(modelId, config);
        self.postMessage({ type: 'INIT_COMPLETE', epoch, seq });
        break;
      }

      case 'GENERATE': {
        const { messages, maxTokens, temperature, topP } = payload;
        const response = await engine.chat.completions.create({
          messages,
          max_tokens: maxTokens,
          temperature,
          top_p: topP,
          stream: true,
        });

        let fullText = '';
        for await (const chunk of response) {
          const token = chunk.choices[0]?.delta?.content || '';
          fullText += token;
          self.postMessage({ type: 'TOKEN', payload: token, epoch, seq });
        }

        self.postMessage({ type: 'GENERATE_COMPLETE', payload: { text: fullText }, epoch, seq });
        break;
      }

      case 'ABORT': {
        if (engine) {
          engine.interruptGenerate();
        }
        self.postMessage({ type: 'ABORT_COMPLETE', epoch, seq });
        break;
      }

      case 'HEALTHCHECK': {
        self.postMessage({
          type: 'HEALTHCHECK_RESPONSE',
          payload: { ok: true, now: Date.now() },
          epoch,
          seq,
        });
        break;
      }

      default:
        console.warn('[Worker] Unknown message type:', type);
    }
  } catch (error) {
    self.postMessage({
      type: 'ERROR',
      payload: { message: error.message, stack: error.stack },
      epoch,
      seq,
    });
  }
};
`,
    },
  ],
  wasm: [
    {
      name: 'wasm-worker.js',
      content: `/**
 * WASM Worker ‚Äî External worker for Transformers.js WASM inference.
 * Generated by @cohesiumai/cli eject-worker
 * CDC v2026.8 ¬ß16.4
 */

// Dynamic import for Transformers.js
let pipeline = null;
let generator = null;

self.onmessage = async (event) => {
  const { type, payload, epoch, seq } = event.data;

  try {
    switch (type) {
      case 'INIT': {
        const { modelId } = payload;
        
        // Import Transformers.js dynamically
        const transformers = await import('https://cdn.jsdelivr.net/npm/@huggingface/transformers@3.0.0/dist/transformers.min.js');
        pipeline = transformers.pipeline;
        
        generator = await pipeline('text-generation', modelId, {
          device: 'wasm',
          dtype: 'q4',
        });
        
        self.postMessage({ type: 'INIT_COMPLETE', epoch, seq });
        break;
      }

      case 'GENERATE': {
        const { prompt, maxTokens, temperature, topP } = payload;
        
        const result = await generator(prompt, {
          max_new_tokens: maxTokens,
          temperature,
          top_p: topP,
          do_sample: true,
        });
        
        const generated = Array.isArray(result) ? result[0] : result;
        const text = generated?.generated_text || '';
        
        self.postMessage({
          type: 'GENERATE_COMPLETE',
          payload: { text: text.slice(prompt.length) },
          epoch,
          seq,
        });
        break;
      }

      case 'HEALTHCHECK': {
        self.postMessage({
          type: 'HEALTHCHECK_RESPONSE',
          payload: { ok: true, now: Date.now() },
          epoch,
          seq,
        });
        break;
      }

      default:
        console.warn('[Worker] Unknown message type:', type);
    }
  } catch (error) {
    self.postMessage({
      type: 'ERROR',
      payload: { message: error.message, stack: error.stack },
      epoch,
      seq,
    });
  }
};
`,
    },
  ],
};

export async function ejectWorker(options: EjectWorkerOptions): Promise<void> {
  const { output, force, provider } = options;

  console.log(chalk.blue('\\nüöÄ browser-ai eject-worker\\n'));
  console.log(chalk.gray(`  Output directory: ${output}`));
  console.log(chalk.gray(`  Provider: ${provider}`));
  console.log(chalk.gray(`  Force overwrite: ${force}\\n`));

  // Resolve output path
  const outputDir = path.resolve(process.cwd(), output);

  // Create output directory
  await fs.ensureDir(outputDir);

  // Determine which files to copy
  const providers = provider === 'all' ? ['webllm', 'wasm'] : [provider];
  let filesWritten = 0;

  for (const p of providers) {
    const files = WORKER_FILES[p as keyof typeof WORKER_FILES];
    if (!files) {
      console.log(chalk.yellow(`  ‚ö† Unknown provider: ${p}`));
      continue;
    }

    for (const file of files) {
      const filePath = path.join(outputDir, file.name);
      const exists = await fs.pathExists(filePath);

      if (exists && !force) {
        console.log(chalk.yellow(`  ‚è≠ Skipped (exists): ${file.name}`));
        continue;
      }

      await fs.writeFile(filePath, file.content, 'utf-8');
      console.log(chalk.green(`  ‚úì Created: ${file.name}`));
      filesWritten++;
    }
  }

  // Create config helper
  const configPath = path.join(outputDir, 'browser-ai.config.js');
  const configContent = `/**
 * Browser AI worker configuration.
 * Generated by @cohesiumai/cli eject-worker
 * 
 * Usage in your app:
 * 
 *   import { createBrowserAI } from '@cohesiumai/core';
 *   import workerConfig from './public/browser-ai/browser-ai.config.js';
 *   
 *   const ai = createBrowserAI({
 *     providerPolicy: { order: ['webllm', 'mock'] },
 *     publicBaseUrl: '/browser-ai',
 *     ...workerConfig,
 *   });
 */

export default {
  // External worker URLs (relative to publicBaseUrl)
  workerUrls: {
    webllm: './webllm-worker.js',
    wasm: './wasm-worker.js',
  },
  
  // Recommended headers for your server
  // Add these to your vite.config.js or next.config.js
  headers: {
    'Cross-Origin-Embedder-Policy': 'require-corp',
    'Cross-Origin-Opener-Policy': 'same-origin',
  },
};
`;

  if (!(await fs.pathExists(configPath)) || force) {
    await fs.writeFile(configPath, configContent, 'utf-8');
    console.log(chalk.green(`  ‚úì Created: browser-ai.config.js`));
    filesWritten++;
  }

  // Summary
  console.log('\\n' + chalk.blue('‚îÅ'.repeat(50)));
  console.log(chalk.green(`\\n‚úÖ Ejected ${filesWritten} file(s) to ${output}\\n`));
  
  console.log(chalk.white('Next steps:'));
  console.log(chalk.gray('  1. Serve the worker files from your public directory'));
  console.log(chalk.gray('  2. Set publicBaseUrl in your BrowserAI config'));
  console.log(chalk.gray('  3. Add COOP/COEP headers to your server config\\n'));
  
  console.log(chalk.white('Example (Vite):'));
  console.log(chalk.cyan(`
  // vite.config.js
  export default {
    server: {
      headers: {
        'Cross-Origin-Embedder-Policy': 'require-corp',
        'Cross-Origin-Opener-Policy': 'same-origin',
      },
    },
  };
`));
}
